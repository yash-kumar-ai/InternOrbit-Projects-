{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "701fa9e2",
   "metadata": {},
   "source": [
    "\n",
    "# Global Terrorism Analysis — Yearly Incident Count Forecasting\n",
    "**Ready-to-run Jupyter Notebook**\n",
    "\n",
    "This notebook walks through:\n",
    "- Loading the Global Terrorism Database (GTD) CSV (download from Kaggle and place in the working folder)\n",
    "- Cleaning & aggregating to yearly incident counts\n",
    "- Visualizing trends\n",
    "- Forecasting with **ARIMA**, **Prophet**, and **LSTM** (optional deep-learning)\n",
    "- Evaluating model performance and plotting future forecasts\n",
    "\n",
    "**How to use**\n",
    "1. Download the GTD CSV (`globalterrorismdb.csv`) from the Kaggle dataset you provided and place it in the same folder as this notebook, or update the `DATA_PATH` variable below.\n",
    "2. Run all cells in order. Required packages will be installed in the first cell if missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install required packages (run once). Uncomment if running in a fresh environment.\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "packages = [\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"scikit-learn\",\n",
    "    \"statsmodels\",\n",
    "    \"numpy\",\n",
    "    \"prophet\",        # note: package name is 'prophet' for recent versions\n",
    "    \"tensorflow\",\n",
    "    \"keras\",\n",
    "    \"tqdm\"\n",
    "]\n",
    "\n",
    "# If you're running on Colab you might want to use a fresh kernel after installing.\n",
    "for p in packages:\n",
    "    try:\n",
    "        __import__(p.split(\"==\")[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Installing {p}...\")\n",
    "        install(p)\n",
    "print(\"Done. If installations occurred, restart the kernel and run again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dece5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "# Set this to the CSV file path you downloaded from Kaggle\n",
    "DATA_PATH = \"globalterrorismdb.csv\"  # <<-- change if your file has a different name or path\n",
    "\n",
    "# Quick check\n",
    "print('Working directory:', os.getcwd())\n",
    "print('Looking for data file at DATA_PATH =', DATA_PATH)\n",
    "assert os.path.exists(DATA_PATH), f\"Data file not found at {DATA_PATH}. Please download GTD CSV and update DATA_PATH.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eddacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset (the GTD CSV is large; set low_memory False to avoid dtype warnings)\n",
    "df = pd.read_csv(DATA_PATH, encoding='ISO-8859-1', low_memory=False)\n",
    "print('Rows, columns:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df85691",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The GTD uses 'iyear' for incident year. Some datasets may include placeholder or missing values.\n",
    "# We'll aggregate incident *rows* per year (one row = one incident record).\n",
    "# First examine iyear distribution and problematic values:\n",
    "print('Unique iyear examples:', sorted(df['iyear'].dropna().unique())[:10])\n",
    "\n",
    "# Group by year (drop rows where iyear is missing or invalid)\n",
    "yearly = df[df['iyear'].notna()].groupby('iyear').size().reset_index(name='attacks')\n",
    "yearly = yearly.sort_values('iyear').set_index('iyear')\n",
    "yearly.index = pd.to_datetime(yearly.index.astype(int), format='%Y')\n",
    "yearly = yearly.asfreq('Y')  # ensures continuous yearly index\n",
    "\n",
    "# Fill any missing years with 0 (if dataset has no incidents recorded for that year)\n",
    "yearly['attacks'] = yearly['attacks'].fillna(0).astype(int)\n",
    "\n",
    "print(yearly.head(15))\n",
    "plt.plot(yearly.index.year, yearly['attacks'], marker='o')\n",
    "plt.title('Global Terrorist Attacks per Year — Raw Counts')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Recorded Incidents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We'll hold out the last 5 years for evaluation by default\n",
    "HOLDOUT_YEARS = 5\n",
    "train = yearly.iloc[:-HOLDOUT_YEARS]\n",
    "test = yearly.iloc[-HOLDOUT_YEARS:]\n",
    "\n",
    "print('Train years:', train.index.year.min(), '-', train.index.year.max())\n",
    "print('Test years :', test.index.year.min(), '-', test.index.year.max())\n",
    "\n",
    "plt.plot(train.index.year, train['attacks'], label='Train', marker='o')\n",
    "plt.plot(test.index.year, test['attacks'], label='Test', marker='o')\n",
    "plt.legend()\n",
    "plt.title('Train / Test split (yearly counts)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a7e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ARIMA forecasting\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "series = train['attacks']\n",
    "\n",
    "# ADF test for stationarity\n",
    "adf_res = adfuller(series)\n",
    "print('ADF statistic:', adf_res[0])\n",
    "print('p-value:', adf_res[1])\n",
    "\n",
    "# We'll try a simple differencing if non-stationary\n",
    "d = 0 if adf_res[1] < 0.05 else 1\n",
    "print('Using d =', d)\n",
    "\n",
    "# Choose p and q using a simple grid search (small range to keep compute light)\n",
    "best_aic = np.inf\n",
    "best_order = None\n",
    "best_m = None\n",
    "for p in range(0,3):\n",
    "    for q in range(0,3):\n",
    "        try:\n",
    "            model = ARIMA(series, order=(p,d,q)).fit(method='innovations_mle')\n",
    "            if model.aic < best_aic:\n",
    "                best_aic = model.aic\n",
    "                best_order = (p,d,q)\n",
    "                best_m = model\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "print('Best ARIMA order:', best_order, 'AIC:', best_aic)\n",
    "arima_model = best_m\n",
    "# Forecast for test period + future 10 years\n",
    "steps = HOLDOUT_YEARS + 10\n",
    "arima_forecast = arima_model.forecast(steps=steps)\n",
    "arima_forecast_index = pd.date_range(start=train.index[-1] + pd.offsets.YearEnd(1), periods=steps, freq='Y')\n",
    "arima_forecast = pd.Series(arima_forecast, index=arima_forecast_index)\n",
    "\n",
    "# Evaluate on test portion\n",
    "arima_pred_test = arima_forecast[:HOLDOUT_YEARS].values\n",
    "rmse_arima = sqrt(mean_squared_error(test['attacks'].values, arima_pred_test))\n",
    "mae_arima = mean_absolute_error(test['attacks'].values, arima_pred_test)\n",
    "print('ARIMA RMSE on test:', rmse_arima, 'MAE:', mae_arima)\n",
    "\n",
    "# Plot\n",
    "plt.plot(yearly.index.year, yearly['attacks'], label='Actual', marker='o')\n",
    "plt.plot(arima_forecast_index.year, arima_forecast.values, label='ARIMA Forecast', linestyle='--')\n",
    "plt.axvline(x=test.index.year.min()-0.5, color='gray', alpha=0.5, linestyle=':')\n",
    "plt.title('ARIMA Forecast (including test & future)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3eead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prophet forecasting\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "except Exception as e:\n",
    "    raise ImportError('Prophet not available. Install `prophet` package and restart the kernel.') from e\n",
    "\n",
    "prophet_df = yearly.reset_index().rename(columns={'iyear':'ds','attacks':'y'})\n",
    "prophet_df['ds'] = pd.to_datetime(prophet_df['ds'].dt.year.astype(str) + '-12-31')  # use year-end as ds for yearly freq\n",
    "\n",
    "m = Prophet(yearly_seasonality=True)\n",
    "m.fit(prophet_df[:-HOLDOUT_YEARS])  # fit on train portion\n",
    "\n",
    "future = m.make_future_dataframe(periods=HOLDOUT_YEARS+10, freq='Y')\n",
    "forecast = m.predict(future)\n",
    "\n",
    "# Extract forecast series and align index\n",
    "prophet_forecast = forecast.set_index('ds')['yhat']\n",
    "prophet_forecast.index = pd.to_datetime(prophet_forecast.index).to_period('Y').to_timestamp('A')  # year-end timestamps\n",
    "\n",
    "# Evaluate on test set (align years)\n",
    "prophet_pred_test = prophet_forecast[-(HOLDOUT_YEARS+10):-10].values  # first HOLDOUT_YEARS of future portion\n",
    "rmse_prophet = sqrt(mean_squared_error(test['attacks'].values, prophet_pred_test))\n",
    "mae_prophet = mean_absolute_error(test['attacks'].values, prophet_pred_test)\n",
    "print('Prophet RMSE on test:', rmse_prophet, 'MAE:', mae_prophet)\n",
    "\n",
    "# Plot prophet forecast\n",
    "m.plot(forecast)\n",
    "plt.title('Prophet Forecast (includes train + forecast)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e081125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LSTM forecasting (sequence model) - optional and more advanced.\n",
    "# We'll build a simple LSTM on the scaled attack counts.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "series_values = yearly['attacks'].values.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled = scaler.fit_transform(series_values.reshape(-1,1)).flatten()\n",
    "\n",
    "# helper to make supervised sequences\n",
    "def create_sequences(data, seq_len=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-seq_len):\n",
    "        X.append(data[i:i+seq_len])\n",
    "        y.append(data[i+seq_len])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "SEQ_LEN = 5\n",
    "X, y = create_sequences(scaled, SEQ_LEN)\n",
    "\n",
    "# Split to train/test using the same HOLDOUT_YEARS logic (keep temporal order)\n",
    "train_size = len(yearly) - HOLDOUT_YEARS\n",
    "X_train, y_train = X[:train_size-SEQ_LEN], y[:train_size-SEQ_LEN]\n",
    "X_test, y_test = X[train_size-SEQ_LEN:], y[train_size-SEQ_LEN:]\n",
    "\n",
    "# reshape for LSTM [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(32, input_shape=(SEQ_LEN,1)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "es = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=8, validation_split=0.1, callbacks=[es], verbose=0)\n",
    "\n",
    "# Forecast iteratively for HOLDOUT_YEARS + 10 future years\n",
    "preds = []\n",
    "last_seq = scaled[-SEQ_LEN:].tolist()\n",
    "for _ in range(HOLDOUT_YEARS+10):\n",
    "    inp = np.array(last_seq[-SEQ_LEN:]).reshape(1, SEQ_LEN, 1)\n",
    "    p = model.predict(inp)[0,0]\n",
    "    preds.append(p)\n",
    "    last_seq.append(p)\n",
    "\n",
    "preds_inv = scaler.inverse_transform(np.array(preds).reshape(-1,1)).flatten()\n",
    "lstm_index = pd.date_range(start=yearly.index[-1] + pd.offsets.YearEnd(1), periods=HOLDOUT_YEARS+10, freq='Y')\n",
    "lstm_series = pd.Series(preds_inv, index=lstm_index)\n",
    "\n",
    "# Evaluate LSTM on test\n",
    "lstm_pred_test = lstm_series[:HOLDOUT_YEARS].values\n",
    "rmse_lstm = sqrt(mean_squared_error(test['attacks'].values, lstm_pred_test))\n",
    "mae_lstm = mean_absolute_error(test['attacks'].values, lstm_pred_test)\n",
    "print('LSTM RMSE on test:', rmse_lstm, 'MAE:', mae_lstm)\n",
    "\n",
    "# Plot LSTM forecast\n",
    "plt.plot(yearly.index.year, yearly['attacks'], label='Actual', marker='o')\n",
    "plt.plot(lstm_series.index.year, lstm_series.values, label='LSTM Forecast', linestyle='--')\n",
    "plt.legend(); plt.title('LSTM Forecast (iterative)'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa5786",
   "metadata": {},
   "source": [
    "\n",
    "## Model Comparison & Next Steps\n",
    "\n",
    "- The notebook fits **ARIMA**, **Prophet**, and an **LSTM** model (LSTM is optional but included for completeness).\n",
    "- Each model provides RMSE/MAE on the held-out years for easy comparison.\n",
    "- **Next steps / improvements**:\n",
    "  - Add exogenous regressors (political indicators, GDP, conflict events) for better forecasting.\n",
    "  - Use cross-validation on time series (walk-forward validation) instead of a single holdout.\n",
    "  - Improve LSTM with hyperparameter search, or try Transformers for time series (e.g., Temporal Fusion Transformer).\n",
    "  - Build an interactive dashboard with Streamlit or Plotly Dash to let users choose models and horizons.\n",
    "\n",
    "**End of notebook.**\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
